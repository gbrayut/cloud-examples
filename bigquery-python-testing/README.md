# BigQuery Python Testing

## Overview

[BigQuery](https://cloud.google.com/bigquery/docs) is Google Cloud's fully managed data warehouse that lets you run analytics over vast amounts of data in "near real time". That last qualifier is important, as it means BigQuery is usually a better fit for batch/ad hoc queries and it is not really designed for serving low-latency indexed lookups like you often see in Cloud SQL, Spanner, Memorystore (Redis/Memcached), or Bigtable. BigQuery also has a fairly low [concurrent queries](https://cloud.google.com/bigquery/quotas#query_jobs:~:text=run%20up%20to%20100%20concurrent%20interactive%20queries) limit (initially set to 100 when using on-demand pricing) that can often cause errors during peak events when serving real time requests directly from BigQuery.

Here we will do some baseline testing to see how different usage patterns perform and the many factors that can affect BigQuery job duration.

## General Best Practices

There are two primary ways to access Google BigQuery when using Python:

* Direct [BigQuery REST API](https://cloud.google.com/bigquery/docs/reference/rest) access via [google-api-python-client](https://github.com/googleapis/google-api-python-client). This autogenerated library is considered complete and in maintenance mode.

* The [Cloud Client Libraries](https://cloud.google.com/apis/docs/client-libraries-explained) provide simplifications that significantly reduce the amount of code you need to write and make it easier to access Google Cloud APIs from a supported language.

The [google-cloud-bigquery](https://cloud.google.com/python/docs/reference/bigquery/latest) Client library for Python provides bigquery.Client() and client.query(query) methods that are the recommended option for accessing Cloud APIs programmatically. When making requests from the same server you should try to [reuse the same client object](https://cloud.google.com/apis/docs/client-libraries-best-practices) for many requests when possible, instead of creating a new one for every request. The initial request made by an instance of a session client performs authentication, authorization, and access token generation which can add sizable overhead. Also accessing BigQuery datasets from outside of GCP or cross-region from inside GCP can add additional latency (See https://gcping.com/ or the Network Intelligence [Performance Dashboard](https://console.cloud.google.com/net-intelligence/performance/dashboard/latency) to estimate regional latency).

## Basic connection baseline testing

The [Using BigQuery with Python](https://codelabs.developers.google.com/codelabs/cloud-bigquery-python#8) codelab shows an example of how to run a query and display some of the [QueryJob](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.job.QueryJob) properties. The [02-client-test.py](./02-client-test.py) variant included here lets us do some basic client connection and query testing. Due to [BigQuery's architecture](https://cloud.google.com/blog/products/data-analytics/new-blog-series-bigquery-explained-overview) a lot of variance is expected across different environments and during different times of the day (based on regional load and capacity), but baseline and non-scientific testing should look something like this:

```s
$ python3 /tmp/test.py
Duration: 0:00:00.068000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
Duration: 0:00:00.076000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
Duration: 0:00:00.068000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
The total time for 3       hamlet iterations is 0.6676 and average 0.2225 seconds

Duration: 0:00:00.063000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
Duration: 0:00:00.050000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
Duration: 0:00:00.051000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
The total time for 3   coriolanus iterations is 0.5284 and average 0.1761 seconds

# Two additional tests using 30 iterations and verbose=False, run a few minutes apart
$ python3 /tmp/test.py
The total time for 30       hamlet iterations is 5.7511 and average 0.1917 seconds
The total time for 30   coriolanus iterations is 5.3409 and average 0.1780 seconds
$ python3 /tmp/test.py
The total time for 30       hamlet iterations is 6.5547 and average 0.2185 seconds
The total time for 30   coriolanus iterations is 6.5438 and average 0.2181 seconds
```

This test was re-using the bigquery.Client() from a VM in the same region as the dataset and issuing the most basic noop "SELECT 1" query. The results show that even in this minimalistic case the individual jobs had significant variance in **server side duration (50ms-76ms)** and in **average iteration wall-time (176ms-222ms)** observed by the Python script. The additional tests used 30 iterations and did not include individual job details, but still show a fair amount of variance **(178ms-219ms per iteration)** on back-to-back runs. Switching from the noop query to a more realistic (but still incredibly simple and always cached) testquery shows similar results:

```s
$ python3 /tmp/test.py      # Using testquery FROM `bigquery-public-data.samples.shakespeare`
Duration: 0:00:00.180000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
Duration: 0:00:00.305000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
Duration: 0:00:00.145000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
The total time for 3       hamlet iterations is 1.1219 and average 0.3740 seconds

Duration: 0:00:00.154000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
Duration: 0:00:00.123000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
Duration: 0:00:00.156000
Bytes:    0 | 0
Cached:   True
------------------------------------------------------------
The total time for 3   coriolanus iterations is 0.8183 and average 0.2728 seconds

$ python3 /tmp/test.py
The total time for 30       hamlet iterations is 8.6462 and average 0.2882 seconds
The total time for 30   coriolanus iterations is 9.2709 and average 0.3090 seconds
$ python3 /tmp/test.py
The total time for 30       hamlet iterations is 9.1839 and average 0.3061 seconds
The total time for 30   coriolanus iterations is 8.9079 and average 0.2969 seconds
```

This time there was more work involved parsing and executing the query, which led to higher **server side duration and variance (123ms-305ms)**, client side **average iteration wall-time (273ms-374ms)**, and similar for the longer runs. During peak business hours I even saw one instance of the same basic testquery taking 800ms server side (job.ended-job.created), likely due to "on-demand" resource contention.

And for a final baseline we will try using a client that is fairly far away from the dataset (more than 1000 miles), and using a much slower connection (broadband home Internet vs GCP backbone), to see how NOT reusing the client impacts the duration:

```s
# noop query from outside GCP on broadband connection and NOT reusing the client
$ python3 ./02-client-test.py 
The total time for 30       hamlet iterations is 77.0425 and average 2.5681 seconds
The total time for 30   coriolanus iterations is 56.8843 and average 1.8961 seconds

# exact same test but WITH client only initialized once and then reused
$ python3 ./02-client-test.py 
The total time for 30       hamlet iterations is 7.4879 and average 0.2496 seconds
The total time for 30   coriolanus iterations is 7.6235 and average 0.2541 seconds
```

In this case the individual server side JobQuery durations were similar to previous tests, but by not reusing the bigquery.Client() average iterations took **1896ms-2568ms** client side compared to **250ms-254ms** when the client was reused. In similar tests from another region inside the VPC it was harder to measure the difference, because establishing new/multiple TCP connections is much easier in a less noisy/more stable/high bandwidth environment like a shared Google VPC.

## Next Steps

With a better understanding of how the Python client connects to BigQuery APIs, the next step is [optimizing query performance](https://cloud.google.com/bigquery/docs/best-practices-performance-overview) for real-world workloads. BigQuery has a unique capacity/performance model, and often requires using various combinations of [reservations](https://cloud.google.com/bigquery/docs/reservations-intro)/batching/caching/project isolation to meet individual workload requirements. You can also use [batch queries](https://cloud.google.com/bigquery/docs/running-queries#batch) via priority=bigquery.QueryPriority.BATCH for queries that do not need to run in real time to free up resources for those that do.

## Other Considerations

* More BigQuery [performance tips](https://cloud.google.com/bigquery/docs/api-performance) and [access patterns](https://cloud.google.com/bigquery/docs/pandas-gbq-migration)

* For extremely complex queries, using a [stored procedure](https://cloud.google.com/bigquery/docs/procedures) like [03-getCorpusWordCount.sql](./03-getCorpusWordCount.sql) could see some improved performance by reducing the "bytes on wire" for the request and possibly saving some SQL compilation/parsing time

* Using [BigQuery Storage API](https://cloud.google.com/bigquery/docs/reference/storage/) for high-throughput rpc-based access to BigQuery managed storage

* Application Performance Monitoring using Google [Cloud Trace](https://cloud.google.com/trace/docs/setup/python-ot) and [OpenTelemetry](https://googleapis.dev/python/bigquery/latest/index.html#instrumenting-with-opentelemetry) in Cloud Client Libraries

* Cloud Architecture Center example: [Minimizing real-time prediction serving latency in machine learning](https://cloud.google.com/architecture/minimizing-predictive-serving-latency-in-machine-learning)

* [Query Queues](https://cloud.google.com/bigquery/docs/query-queues) are in preview to help prevent errors due to quota limits, and they also allow tuning of concurrency targets for projects or reservations
